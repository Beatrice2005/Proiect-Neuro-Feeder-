model_architecture:
  hidden_layers: [100, 50]
  activation: "ReLU"
training_params:
  optimizer: "Adam"
  learning_rate: 0.001
  batch_size: 32
  max_epochs: 500
  early_stopping:
    enabled: true
    patience: 10
